{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9917\n",
      "2469\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json as js\n",
    "\n",
    "with open(\"/u/pmpande/author_profiling/fb.json\") as f:\n",
    "    data_fb = pd.DataFrame(js.loads(line) for line in f)\n",
    "f.close()\n",
    "\n",
    "with open(\"/u/pmpande/author_profiling/essays.json\") as f:\n",
    "    data_essays = pd.DataFrame(js.loads(line) for line in f)\n",
    "f.close()\n",
    "\n",
    "print(len(data_fb))\n",
    "print(len(data_essays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_fb.drop(data_fb.head(1).index, inplace=True)\n",
    "data_essays.drop(data_essays.head(1).index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5312626058894716\n",
      "0.4594594594594595\n",
      "0.4245663574021783\n",
      "0.37474788221056876\n",
      "0.7431423961274708\n"
     ]
    }
   ],
   "source": [
    "count1 = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "count4 = 0\n",
    "count5 = 0\n",
    "for row in data_fb.iterrows():\n",
    "    if row[1]['AGR'] == 'y': count1 += 1\n",
    "    if row[1]['CON'] == 'y': count2 += 1\n",
    "    if row[1]['EXT'] == 'y': count3 += 1\n",
    "    if row[1]['NEU'] == 'y': count4 += 1\n",
    "    if row[1]['OPN'] == 'y': count5 += 1\n",
    "print(str(count1/len(data_fb)))\n",
    "print(str(count2/len(data_fb)))\n",
    "print(str(count3/len(data_fb)))\n",
    "print(str(count4/len(data_fb)))\n",
    "print(str(count5/len(data_fb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "rand_fb = random.sample(range(1,len(data_fb)-1),990) \n",
    "rand_essays = random.sample(range(1,len(data_essays)-1),250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test1 = data_fb.iloc[rand_fb].copy()\n",
    "train1 = data_fb.drop(rand_fb)\n",
    "\n",
    "test2 = data_essays.iloc[rand_essays].copy()\n",
    "train2 = data_essays.drop(rand_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train1.drop(train1.columns[[1,7,8,9,10,11]], axis=1, inplace=True)\n",
    "test1.drop(test1.columns[[1,7,8,9,10,11]], axis=1, inplace=True)\n",
    "\n",
    "train2.drop(train2.columns[[1]], axis=1, inplace=True)\n",
    "test2.drop(test2.columns[[1]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "corpus1 = []\n",
    "truth1 = []\n",
    "for row in train1.iterrows():\n",
    "    Y = [0,0,0,0,0]\n",
    "    corpus1.append(row[1]['STATUS'])\n",
    "    if row[1]['AGR'] == 'y': Y[0] = 1\n",
    "    if row[1]['CON'] == 'y': Y[1] = 1\n",
    "    if row[1]['EXT'] == 'y': Y[2] = 1\n",
    "    if row[1]['NEU'] == 'y': Y[3] = 1\n",
    "    if row[1]['OPN'] == 'y': Y[4] = 1\n",
    "    truth1.append(Y)\n",
    "truth1 = np.array(truth1)\n",
    "corpus2 = []\n",
    "truth2 = []\n",
    "for row in train2.iterrows():\n",
    "    Y = [0,0,0,0,0]\n",
    "    corpus2.append(row[1]['STATUS'])\n",
    "    if row[1]['AGR'] == 'y': Y[0] = 1\n",
    "    if row[1]['CON'] == 'y': Y[1] = 1\n",
    "    if row[1]['EXT'] == 'y': Y[2] = 1\n",
    "    if row[1]['NEU'] == 'y': Y[3] = 1\n",
    "    if row[1]['OPN'] == 'y': Y[4] = 1\n",
    "    truth2.append(Y)\n",
    "truth2 = np.array(truth2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(analyzer=\"word\", token_pattern=\"[a-zA-Z]*\", lowercase=True, stop_words=\"english\")\n",
    "x1 = vectorizer1.fit_transform(corpus1)\n",
    "tfidf_transformer1 = TfidfTransformer()\n",
    "X1 = tfidf_transformer1.fit_transform(x1)\n",
    "\n",
    "vectorizer2 = CountVectorizer(analyzer=\"word\", token_pattern=\"[a-zA-Z]*\", lowercase=True, stop_words=\"english\")\n",
    "x2 = vectorizer2.fit_transform(corpus2)\n",
    "tfidf_transformer2 = TfidfTransformer()\n",
    "X2 = tfidf_transformer2.fit_transform(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf1 = DecisionTreeClassifier()\n",
    "clf1_1 = RandomForestClassifier()\n",
    "clf1 = clf1.fit(X1, truth1)\n",
    "clf1_1 = clf1_1.fit(X1, truth1)\n",
    "\n",
    "clf2 = DecisionTreeClassifier()\n",
    "clf2_1 = RandomForestClassifier()\n",
    "clf2 = clf2.fit(X2, truth2)\n",
    "clf2_1 = clf2_1.fit(X2, truth2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data1 = []\n",
    "truth_test1 = []\n",
    "for row in test1.iterrows():\n",
    "    Y = [0,0,0,0,0]\n",
    "    test_data1.append(row[1]['STATUS'])\n",
    "    if row[1]['AGR'] == 'y': Y[0] = 1\n",
    "    if row[1]['CON'] == 'y': Y[1] = 1\n",
    "    if row[1]['EXT'] == 'y': Y[2] = 1\n",
    "    if row[1]['NEU'] == 'y': Y[3] = 1\n",
    "    if row[1]['OPN'] == 'y': Y[4] = 1\n",
    "    truth_test1.append(Y)\n",
    "truth_test1 = np.array(truth_test1)\n",
    "test_data2 = []\n",
    "truth_test2 = []\n",
    "for row in test2.iterrows():\n",
    "    Y = [0,0,0,0,0]\n",
    "    test_data2.append(row[1]['STATUS'])\n",
    "    if row[1]['AGR'] == 'y': Y[0] = 1\n",
    "    if row[1]['CON'] == 'y': Y[1] = 1\n",
    "    if row[1]['EXT'] == 'y': Y[2] = 1\n",
    "    if row[1]['NEU'] == 'y': Y[3] = 1\n",
    "    if row[1]['OPN'] == 'y': Y[4] = 1\n",
    "    truth_test2.append(Y)\n",
    "truth_test2 = np.array(truth_test2)\n",
    "x_test1 = vectorizer1.transform(test_data1)\n",
    "X_test1 = tfidf_transformer1.transform(x_test1)\n",
    "\n",
    "x_test2 = vectorizer2.transform(test_data2)\n",
    "X_test2 = tfidf_transformer2.transform(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output1 = clf1.predict(X_test1)\n",
    "output1_1 = clf1_1.predict(X_test1)\n",
    "output2 = clf2.predict(X_test2)\n",
    "output2_1 = clf2_1.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888888888889\n",
      "0.04606060606060606\n",
      "0.21461734799546392\n",
      "0.817171717172\n",
      "0.06868686868686869\n",
      "0.26208179770229884\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, mean_squared_error\n",
    "\n",
    "print(accuracy_score(truth_test1, output1, normalize=True))\n",
    "print(hamming_loss(truth_test1, output1))\n",
    "print(sqrt(mean_squared_error(truth_test1, output1)))\n",
    "\n",
    "print(accuracy_score(truth_test1, output1_1, normalize=True))\n",
    "print(hamming_loss(truth_test1, output1_1))\n",
    "print(sqrt(mean_squared_error(truth_test1, output1_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932\n",
      "0.032\n",
      "0.17888543819998318\n",
      "0.912\n",
      "0.0384\n",
      "0.19595917942265426\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(truth_test2, output2, normalize=True))\n",
    "print(hamming_loss(truth_test2, output2))\n",
    "print(sqrt(mean_squared_error(truth_test2, output2)))\n",
    "\n",
    "print(accuracy_score(truth_test2, output2_1, normalize=True))\n",
    "print(hamming_loss(truth_test2, output2_1))\n",
    "print(sqrt(mean_squared_error(truth_test2, output2_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
