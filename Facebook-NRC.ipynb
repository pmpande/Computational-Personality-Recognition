{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9917\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json as js\n",
    "\n",
    "with open(\"/u/pmpande/author_profiling/fb.json\") as f:\n",
    "    data_essays = pd.DataFrame(js.loads(line) for line in f)\n",
    "f.close()\n",
    "\n",
    "print(len(data_essays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_essays.drop(data_essays.head(1).index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NRCDict = {}\n",
    "with open(\"NRC-emotion-lexicon-wordlevel-alphabetized-v0.92.txt\",'r') as f:\n",
    "    for line in f:\n",
    "        text = line.split()\n",
    "        if text[2] == '1':\n",
    "            if text[0] in NRCDict:\n",
    "                NRCDict[text[0]] += \"#\" + text[1]\n",
    "            else:\n",
    "                NRCDict[text[0]] = text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for interation 0: 0.225\n",
      "Hamming Loss for interation 0: 0.328\n",
      "RMSE for interation 0: 0.5727128425310541\n",
      "Accuracy for interation 1: 0.194\n",
      "Hamming Loss for interation 1: 0.3452\n",
      "RMSE for interation 1: 0.5875372328627353\n",
      "Accuracy for interation 2: 0.214\n",
      "Hamming Loss for interation 2: 0.32\n",
      "RMSE for interation 2: 0.565685424949238\n",
      "Accuracy for interation 3: 0.218\n",
      "Hamming Loss for interation 3: 0.3172\n",
      "RMSE for interation 3: 0.563205113613149\n",
      "Accuracy for interation 4: 0.205\n",
      "Hamming Loss for interation 4: 0.3332\n",
      "RMSE for interation 4: 0.5772347875864725\n",
      "Accuracy for interation 5: 0.218\n",
      "Hamming Loss for interation 5: 0.3324\n",
      "RMSE for interation 5: 0.576541412215983\n",
      "Accuracy for interation 6: 0.194\n",
      "Hamming Loss for interation 6: 0.3464\n",
      "RMSE for interation 6: 0.5885575587824864\n",
      "Accuracy for interation 7: 0.23\n",
      "Hamming Loss for interation 7: 0.3228\n",
      "RMSE for interation 7: 0.5681549084536717\n",
      "Accuracy for interation 8: 0.231\n",
      "Hamming Loss for interation 8: 0.3296\n",
      "RMSE for interation 8: 0.574108003776293\n",
      "Accuracy for interation 9: 0.216\n",
      "Hamming Loss for interation 9: 0.341\n",
      "RMSE for interation 9: 0.5839520528262573\n",
      "-------------------------------\n",
      "Average accuracy is :0.2145\n",
      "Average haming loss is :0.33158000000000004\n",
      "Average RMSE loss is :0.575768933759734\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import tree\n",
    "from empath import Empath\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "accuracy = 0.0\n",
    "rmse = 0.0\n",
    "h_loss = 0.0\n",
    "for i in range(10):\n",
    "    rand_essays = []\n",
    "    temp_data = data_essays.copy()\n",
    "    rand_essays = random.sample(range(1,len(temp_data)-1),1000)\n",
    "    test = temp_data.iloc[rand_essays].copy()\n",
    "    train = temp_data.drop(rand_essays)\n",
    "    train.drop(train.columns[[1,7,8,9,10,11]], axis=1, inplace=True)\n",
    "    test.drop(test.columns[[1,7,8,9,10,11]], axis=1, inplace=True)\n",
    "    \n",
    "    corpus = []\n",
    "    truth = []\n",
    "    for row in train.iterrows():\n",
    "        Y = [0,0,0,0,0]\n",
    "        corpus.append(row[1]['STATUS'])\n",
    "        if row[1]['AGR'] == 'y': Y[0] = 1\n",
    "        if row[1]['CON'] == 'y': Y[1] = 1\n",
    "        if row[1]['EXT'] == 'y': Y[2] = 1\n",
    "        if row[1]['NEU'] == 'y': Y[3] = 1\n",
    "        if row[1]['OPN'] == 'y': Y[4] = 1\n",
    "        truth.append(Y)\n",
    "    truth = np.array(truth)\n",
    "    feat = []\n",
    "    for row in corpus:\n",
    "        tokens = nltk.word_tokenize(row)\n",
    "        feat_row = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "        for word in tokens:\n",
    "            if word in NRCDict:\n",
    "                category = NRCDict[word].split(\"#\")\n",
    "                if \"anger\" in category: feat_row[0] += 1\n",
    "                if \"anticipation\" in category: feat_row[1] += 1\n",
    "                if \"disgust\" in category: feat_row[2] += 1\n",
    "                if \"fear\" in category: feat_row[3] += 1\n",
    "                if \"joy\" in category: feat_row[4]+= 1\n",
    "                if \"negative\" in category: feat_row[5] += 1\n",
    "                if \"positive\" in category: feat_row[6] += 1\n",
    "                if \"sadness\" in category: feat_row[7] += 1\n",
    "                if \"surprise\" in category: feat_row[8] += 1\n",
    "                if \"trust\" in category: feat_row[9] += 1\n",
    "            else: continue\n",
    "        feat.append(feat_row)\n",
    "    feat = np.array(feat)\n",
    "    feat_norm = normalize(feat, axis=1, norm='l1')\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(feat_norm, truth)\n",
    "    \n",
    "    test_data = []\n",
    "    truth_test = []\n",
    "    for row in test.iterrows():\n",
    "        Y = [0,0,0,0,0]\n",
    "        test_data.append(row[1]['STATUS'])\n",
    "        if row[1]['AGR'] == 'y': Y[0] = 1\n",
    "        if row[1]['CON'] == 'y': Y[1] = 1\n",
    "        if row[1]['EXT'] == 'y': Y[2] = 1\n",
    "        if row[1]['NEU'] == 'y': Y[3] = 1\n",
    "        if row[1]['OPN'] == 'y': Y[4] = 1\n",
    "        truth_test.append(Y)\n",
    "    truth_test = np.array(truth_test)\n",
    "    test_feat = []\n",
    "    for row in test_data:\n",
    "        tokens = nltk.word_tokenize(row)\n",
    "        feat_row = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "        for word in tokens:\n",
    "            if word in NRCDict:\n",
    "                category = NRCDict[word].split(\"#\")\n",
    "                if \"anger\" in category: feat_row[0] += 1\n",
    "                if \"anticipation\" in category: feat_row[1] += 1\n",
    "                if \"disgust\" in category: feat_row[2] += 1\n",
    "                if \"fear\" in category: feat_row[3] += 1\n",
    "                if \"joy\" in category: feat_row[4] += 1\n",
    "                if \"negative\" in category: feat_row[5] += 1\n",
    "                if \"positive\" in category: feat_row[6] += 1\n",
    "                if \"sadness\" in category: feat_row[7] += 1\n",
    "                if \"surprise\" in category: feat_row[8] += 1\n",
    "                if \"trust\" in category: feat_row[9] += 1\n",
    "            else: continue\n",
    "        test_feat.append(feat_row)\n",
    "    test_feat = np.array(test_feat)\n",
    "    test_feat_norm = normalize(test_feat, axis=1, norm='l1')\n",
    "    \n",
    "    output = clf.predict(test_feat_norm)\n",
    "    err = sqrt(mean_squared_error(truth_test, output))\n",
    "    acc = accuracy_score(truth_test, output, normalize=True)\n",
    "    loss = hamming_loss(truth_test, output)\n",
    "    accuracy += acc\n",
    "    rmse += err\n",
    "    h_loss += loss\n",
    "    print(\"Accuracy for interation \" + str(i) + \": \" + str(acc))\n",
    "    print(\"Hamming Loss for interation \" + str(i) + \": \" + str(loss))\n",
    "    print(\"RMSE for interation \" + str(i) + \": \" + str(err))\n",
    "    del test\n",
    "    del train\n",
    "    del temp_data\n",
    "print(\"-------------------------------\")\n",
    "print(\"Average accuracy is :\" + str(accuracy/10))\n",
    "print(\"Average haming loss is :\" + str(h_loss/10))\n",
    "print(\"Average RMSE loss is :\" + str(rmse/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
